{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python et le calcul scientifique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La plupart des langages interprétés ont mauvaise presse dans le domaine du calcul scientifique.\n",
    "Réputés lents et peu fiables (du fait du typage dynamique), leur adoption dans l'industrie a été\n",
    "tardive (aujourd'hui encore, on préfèrera largement des bases de code en C, C++, ou en java).\n",
    "\n",
    "Pour le calcul numérique, la référence a longtemps été le Fortran, plus adapté à la manipulation\n",
    "des array que le C. D'ailleur, la plupart des librairies de calcul sont fondés sur des sous-routines\n",
    "Fortran qui font références en algèbre linéaire (blas, scalapack, lapack...).\n",
    "\n",
    "Matlab est arrivé concurencer le Fortran, en particulier dans le domaine de l'analyse de signal, et\n",
    "était à l'époque une des seuls alternatives pour écrire des codes suffisement performants sans s'encombrer\n",
    "d'une syntaxe complexe, ni devoir gérer les spécificités de la machine.\n",
    "\n",
    "Ce dernier language est un DSL pour *Domain Specific Language*, c'est à dire un langage de programmation\n",
    "dédié à un champs d'application restreint. Il fourni aux scientifiques des outils particulièrements adaptés\n",
    "pour l'algèbre linéaire, outils qui manquait cruellement à Python à ses débuts.\n",
    "\n",
    "Ce dernier, au contraire de Matlab, est un langage généraliste. Il est capable de manipuler des nombres,\n",
    "de servir de back-end à un site web, a récemment trouvé sa place dans l'embarqué et l'IOT, est capable d'extraire\n",
    "des informations d'un site web etc. Son essort et sa bonne réputation dans la communauté scientifique date de\n",
    "la création de `numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La naissance de numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy (pour Numerical Python) est née en 1995, soit 4 ans après la première version de Python. (matlab date de 1984, Fortran de 1954...). Il consiste en un ensemble de routines permettant de manipuler des tableaux de valeurs numériques (mais aussi potentiellement de chaines de caractères ou de booléens par exemple). Ces routines sont implémenté en C, ce qui permet un gain de temps notable comparé à une implémentation en pure Python, en particulier si le code est **vectorisé**.\n",
    "\n",
    "De cette façon, des fonctionnalités analogues à cette disponible sous Matlab sont disponible, tout en s'inscrivant dans un langage moderne et généraliste. Contrairement à Matlab, tout ne tourne pas autour de la matrice mais de l'array à N dimension. Les opérations spécifiques aux vecteurs et matrices sont disponibles mais la plupart des opérations ont étés étendus de façon à fonctionner indifférement du nombre de dimension du tableau. Dans cet esprit, les opérateurs appliqués aux tableaux fonctionnent éléments par éléments par défaut, et la multiplication matricielle est une opération à part (accessible avec `@` dans les versions récentes de Python). \n",
    "\n",
    "Lorsque NumPy est passé en version 1.0, une partie de ses fonctionnalités ont été retirés, et ce dans l'objectif d'en faire une brique de base minimale. Les fonctionnalités qui n'étaient pas indispensables ont été regroupés dans la librairie SciPy (Scientific Python). Celle ci se comporte donc comme une grosse boîte à outil pour scientifique, fondés sur NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scipy, une large toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scipy est une large boite à outil pour scientifiques de tous domaines. On y retrouve de quoi résoudre des équations differentielles, des systèmes d'équations linéaires -ou non-linéaires-, de manipuler des matrices creuses, de faire de l'intégration numérique, de manipuler des notions statistiques et de faire du traitement du signal.\n",
    "\n",
    "Si le plus gros des besoins est couvert par Scipy, les `scikit` couvrent des domaines plus spécifiques. Citons par exemple `scikit-learn` pour l'apprentissage machine, `scikit-image` pour le traitement d'image ou `scikit-fdiff` pour la résolution d'équations différentielles partielle (dont j'en suis l'auteur). D'autres librairies tierces peuvent compléter les besoins (OpenCV, DEAP, fenics, SAlib pour n'en citer qu'une petite partie).\n",
    "\n",
    "- constants: physical constants and conversion factors\n",
    "- cluster: hierarchical clustering, vector quantization, K-means\n",
    "- fftpack: Discrete Fourier Transform algorithms\n",
    "- integrate: numerical integration routines\n",
    "- interpolate: interpolation tools\n",
    "- io: data input and output\n",
    "- lib: Python wrappers to external libraries\n",
    "- linalg: linear algebra routines\n",
    "- misc: miscellaneous utilities (e.g. image reading/writing)\n",
    "- ndimage: various functions for multi-dimensional image processing\n",
    "- optimize: optimization algorithms including linear programming\n",
    "- signal: signal processing tools\n",
    "- sparse: sparse matrix and related algorithms\n",
    "- spatial: KD-trees, nearest neighbors, distance functions\n",
    "- special: special functions\n",
    "- stats: statistical functions\n",
    "- weave: tool for writing C/C++ code as Python multiline strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les temps modernes, Pandas et analyse de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'analyse numérique \"classique\" est couverte par scipy et les scikits. Mais il reste un pan entier d'application, qui correspond au traitement des données et qui est la spécialité du langage R (un autre DSL spécialisé dans les statistiques et la science des données).\n",
    "\n",
    "Pandas est un \"nouveau venu\" dans l'écosystème Python (première release: Janvier 2008). Il se focalise sur la gestion et l'analyse des données, depuis leur extraction (pour les cas les plus basiques, d'autres outils existent pour des besoin spécifiques comme le scraping de données sur le web), le nettoyage, et l'ensemble des opérations qu'il est possible de faire sur des données tabulaires:\n",
    "- Lecture des données (csv, xls, html, HDF, SQL...)\n",
    "- Gestion de données manquantes\n",
    "- Analyse statistique des données\n",
    "- Indexation complexe\n",
    "- Aggrégats\n",
    "- Rééchantillonage\n",
    "- Changement de forme, pivot, tableau croisés\n",
    "- Écriture des résultats (csv, xls, html, HDF, SQL...)\n",
    "\n",
    "Derrière le décors, les données sont gérés par numpy (chaques colonnes d'un DataFrame pandas est un tableau numpy), ce qui permet une performance acceptable. Mais la surcouche pandas permet de faire très facilement les opérations décrites plus haut.\n",
    "\n",
    "A noter qu'un équivalent existe pour les données multi-dimensionnels : `xarray`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aujourd'hui et demain, le machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La grande popularité de Python provient également de l'essort du Machine Learning. Un nombre croissant de librairies permettent d'utiliser des algorithme de classification et de prédiction, dont `scikit-learn`, ou plus spécifiquement pour le développement de réseaux de neurone avec `tensor-flow` / `keras`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La grande force du stack scientifique Python est d'avoir données des outils performants tout en conservant la souplesse d'un langage moderne. Il est bien entendu possible d'utiliser des outils plus rapides mais dont la prise en main et le temps de développement prendra beaucoup plus de temps.\n",
    "\n",
    "Les bases de codes doivent être prioritairement facile à écrire, facile à maintenir. Seul une petite fraction du code est critique pour la performance, et cette fraction est portés par des librairies spécialisés et performantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
